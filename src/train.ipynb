{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NTupQaERWVs4"
      },
      "outputs": [],
      "source": [
        "from transformer import Transformer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import importlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bicUHq0SWVs5"
      },
      "outputs": [],
      "source": [
        "START_TOKEN = '<s>'\n",
        "END_TOKEN = '<\\s>'\n",
        "PADDING_TOKEN = '<pad>'\n",
        "english_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "                    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
        "                    ':', '<', '=', '>', '?', '@', ';',\n",
        "                    '[', '\\\\', ']',\n",
        "                    '^', '_', '`',\n",
        "                    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "                    'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
        "                    'y', 'z',\n",
        "                    '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN\n",
        "                    ]\n",
        "\n",
        "persian_vocabulary = [\n",
        "START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "'0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ';',\n",
        "':', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`',\n",
        "'آ', 'ا', 'ب', 'پ', 'ت', 'ث', 'ج', 'چ', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'ژ', 'س', 'ش',\n",
        "'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ک', 'گ', 'ل', 'م', 'ن', 'و', 'ه', 'ی',\n",
        "'ء', 'ۀ', 'ؤ', 'ي', 'ك', 'ة', '‌', 'ٔ', 'ى', PADDING_TOKEN, END_TOKEN\n",
        "]\n",
        "index_to_persian = {k:v for k,v in enumerate(persian_vocabulary)}\n",
        "persian_to_index = {v:k for k,v in enumerate(persian_vocabulary)}\n",
        "index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n",
        "english_to_index = {v:k for k,v in enumerate(english_vocabulary)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tDs69OfIWVs5",
        "outputId": "ee0c0831-e8cb-4cf8-adc5-9180834cb9ef"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-88f1fd35-b5dd-423c-82f0-b3cb4ecb744f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>persian</th>\n",
              "      <th>english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>گلدان روی میز چای حاضر و آماده بود.</td>\n",
              "      <td>the vase filled with water was ready in the ce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>آن وقت قاضی چه کرد؟</td>\n",
              "      <td>What did the justice do?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>به روزگار فيلماي ؛ نقطه تلاقي ؛ ماري کثيف يا ه...</td>\n",
              "      <td>vanishing point days , the dirty mary crazy la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>افراد مورد اعتماد زیردستهایشان به عنوان سرپرست...</td>\n",
              "      <td>with the trust of his subordinates as the head...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>زودتر برویم. من حاضرم.</td>\n",
              "      <td>I am ready, my son, said Mercedes.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88f1fd35-b5dd-423c-82f0-b3cb4ecb744f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-88f1fd35-b5dd-423c-82f0-b3cb4ecb744f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-88f1fd35-b5dd-423c-82f0-b3cb4ecb744f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-91d015e7-cc2a-4d0a-adfe-727f33ac4cb7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-91d015e7-cc2a-4d0a-adfe-727f33ac4cb7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-91d015e7-cc2a-4d0a-adfe-727f33ac4cb7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Unnamed: 0                                            persian  \\\n",
              "0           0                گلدان روی میز چای حاضر و آماده بود.   \n",
              "1           1                                آن وقت قاضی چه کرد؟   \n",
              "2           2  به روزگار فيلماي ؛ نقطه تلاقي ؛ ماري کثيف يا ه...   \n",
              "3           3  افراد مورد اعتماد زیردستهایشان به عنوان سرپرست...   \n",
              "4           4                             زودتر برویم. من حاضرم.   \n",
              "\n",
              "                                             english  \n",
              "0  the vase filled with water was ready in the ce...  \n",
              "1                           What did the justice do?  \n",
              "2  vanishing point days , the dirty mary crazy la...  \n",
              "3  with the trust of his subordinates as the head...  \n",
              "4                 I am ready, my son, said Mercedes.  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_excel('shortened_dataset.xlsx')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yoAZCPOZWVs6"
      },
      "outputs": [],
      "source": [
        "df['english'] = df['english'].astype(str)\n",
        "df['persian'] = df['persian'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rg_vAttHWVs6"
      },
      "outputs": [],
      "source": [
        "def helper_english(x:str):\n",
        "        for c in x:\n",
        "            if not c in english_vocabulary:\n",
        "                x = x.replace(c, '')\n",
        "        return x\n",
        "\n",
        "def helper_persian(x:str):\n",
        "    for c in x:\n",
        "        if not c in persian_vocabulary:\n",
        "            x = x.replace(c, '')\n",
        "    return x\n",
        "\n",
        "df['english'] = df['english'].apply(str.lower)\n",
        "df['english'] = df['english'].apply(helper_english)\n",
        "df['persian'] = df['persian'].apply(helper_persian)\n",
        "persian_sentences = df['persian'].to_list()\n",
        "english_sentences = df['english'].to_list()\n",
        "enlish_sentences = df['english'].to_list()\n",
        "persian_sentences = df['persian'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KqNsgBCZWVs6"
      },
      "outputs": [],
      "source": [
        "model_dim = 512\n",
        "batch_size = 64\n",
        "hidden_fc = 2048\n",
        "num_heads = 8\n",
        "drop_prob = 0.1\n",
        "num_layers = 2\n",
        "max_sequence_length = 200\n",
        "persian_vocab_size = len(persian_vocabulary)\n",
        "\n",
        "transformer = Transformer((batch_size, max_sequence_length, model_dim),\n",
        "                          model_dim,\n",
        "                          hidden_fc,\n",
        "                          num_heads,\n",
        "                          drop_prob,\n",
        "                          num_layers,\n",
        "                          max_sequence_length,\n",
        "                          persian_vocab_size,\n",
        "                          english_to_index,\n",
        "                          persian_to_index,\n",
        "                          START_TOKEN,\n",
        "                          END_TOKEN,\n",
        "                          PADDING_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "y7Phw_xUWVs6"
      },
      "outputs": [],
      "source": [
        "class TranslateDataset(Dataset):\n",
        "    def __init__(self, english_sentences, persian_sentences):\n",
        "        super().__init__()\n",
        "        self.english_sentences = english_sentences\n",
        "        self.persian_sentences = persian_sentences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.persian_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.english_sentences[idx], self.persian_sentences[idx]\n",
        "\n",
        "\n",
        "dataset = TranslateDataset(english_sentences, persian_sentences)\n",
        "train_loader = DataLoader(dataset, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VR31A-gmWVs6"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=persian_to_index[PADDING_TOKEN])\n",
        "for params in transformer.parameters():\n",
        "    if params.dim() > 1:\n",
        "        nn.init.xavier_uniform_(params)\n",
        "\n",
        "optim = torch.optim.Adam(transformer.parameters(), lr=1e-4)\n",
        "device = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KXc5UcS5WVs6"
      },
      "outputs": [],
      "source": [
        "\n",
        "NEG_INFTY = -1e9\n",
        "\n",
        "def create_masks(eng_batch, persian_batch, number_of_heads):\n",
        "    num_sentences = len(eng_batch)\n",
        "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length], True)\n",
        "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
        "\n",
        "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length], False)\n",
        "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length], False)\n",
        "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length], False)\n",
        "\n",
        "    for idx in range(num_sentences):\n",
        "        eng_sentence_length, persian_sentence_length = len(eng_batch[idx]), len(persian_batch[idx])\n",
        "        eng_chars_to_padding_mask = np.arange(eng_sentence_length, max_sequence_length)\n",
        "        persian_chars_to_padding_mask = np.arange(persian_sentence_length, max_sequence_length)\n",
        "\n",
        "        encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n",
        "        encoder_padding_mask[idx, :, eng_chars_to_padding_mask] = True\n",
        "\n",
        "        decoder_padding_mask_self_attention[idx, persian_chars_to_padding_mask, :] = True\n",
        "        decoder_padding_mask_self_attention[idx, :, persian_chars_to_padding_mask] = True\n",
        "\n",
        "        decoder_padding_mask_cross_attention[idx, persian_chars_to_padding_mask, :] = True\n",
        "        decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n",
        "\n",
        "\n",
        "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
        "    decoder_self_attention_mask = torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
        "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
        "\n",
        "\n",
        "    encoder_self_attention_mask = encoder_self_attention_mask.unsqueeze(1).repeat(1, number_of_heads, 1, 1)\n",
        "    decoder_self_attention_mask = decoder_self_attention_mask.unsqueeze(1).repeat(1, number_of_heads, 1, 1)\n",
        "    decoder_cross_attention_mask = decoder_cross_attention_mask.unsqueeze(1).repeat(1, number_of_heads, 1, 1)\n",
        "\n",
        "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1NNlzsiWVs7",
        "outputId": "90ee959b-969c-44c7-9b4d-20f4cd3b44a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "loss at batch number 0 : 0.00036815801286138594\n",
            "English: the vase filled with water was ready in the center of the tea table.\n",
            "Persian Translation: گلدان روی میز چای حاضر و آماده بود.\n",
            "Persian Prediction: گلمان روی این آا  ب  ردو آماده بود.\n",
            "-------------------------------------------\n",
            "loss at batch number 100 : 0.0003917920112144202\n",
            "English: but even here, while on the scaffolding, in the midst of a talk explaining the future arrangements of the house, he interrupted himself:\n",
            "Persian Translation: ولی در میان این سخنان نیز هنگامی که نقشه خانه را برای پی‌یر توضیح می‌داد یک مرتبه روی چوب بست ایستاده گفت:\n",
            "Persian Prediction: ولی در میین انن ارویی ایز هن امی که ن یه باند ری برای پی‌ار بییین بی‌ه ن بک مرتبه روی بر ربات ب  ت ن. درت.\n",
            "-------------------------------------------\n",
            "loss at batch number 200 : 0.00030965477344579995\n",
            "English: don't play with me like a cat with a mouse.\n",
            "Persian Translation: چرا مثل گربه‌ای که با موش بازی کند با من رفتار می‌کنید\n",
            "Persian Prediction: چرا مير گراه هی به به بوش بالی برد را بن بوتار اا‌کنید\n",
            "-------------------------------------------\n",
            "loss at batch number 300 : 0.0003670540754683316\n",
            "English: while the husband pondered and combined\n",
            "Persian Translation: هنگامی‌که شوهر خودش را می‌جوید و کارها را پیش خود جفت‌وجور می‌کرد.\n",
            "Persian Prediction: هنگامی که شواا آو   را می‌جواد و چانه  را کین سود جفت‌وجود می کرد.\n",
            "-------------------------------------------\n",
            "loss at batch number 400 : 0.0003662624803837389\n",
            "English: ill fight it for you all the way to the privy council if necessary.\n",
            "Persian Translation: اگر لازم باشد تا شورای سلطنتی پرونده را دنبال می‌کنم.\n",
            "Persian Prediction: اگر لا م داشت کا ا   ی گلطنته کرانده با دامار می‌کنم.\n",
            "-------------------------------------------\n",
            "loss at batch number 500 : 0.0003792889474425465\n",
            "English: zack bradley just punching in on the bright .\n",
            "Persian Translation: زاک بردلي اون صبح کارتشو کشيد .\n",
            "Persian Prediction: زاز برالي رون كر  بهستيد کشيي .\n",
            "-------------------------------------------\n",
            "loss at batch number 600 : 0.00036477294634096324\n",
            "English: i will obey your every word.\n",
            "Persian Translation: من هر فرماني که بديد اطاعت مي کنم\n",
            "Persian Prediction: من هر برم  ي به با  اا وعت مي .ند\n",
            "-------------------------------------------\n",
            "loss at batch number 700 : 0.00038671554648317397\n",
            "English: not even noticing the yellow butterflies that were still accompanying her.\n",
            "Persian Translation: او حتی متوجه پروانه‌های زردرنگی که هنوز هم در بالای سرش پرواز می‌کردند نشد.\n",
            "Persian Prediction: او حتی مووبه برو ن  های زردر گی به هندی نا در بهرای سرش لروان می کر ند هدد.\n",
            "-------------------------------------------\n",
            "loss at batch number 800 : 0.000409132830100134\n",
            "English: that we all know it, and all invent means of deceiving each other.\n",
            "Persian Translation: همه‌مان را این را می‌دانیم و سعی می‌کنیم وسایلی اختراع کنیم که خودمان را گول بزنیم.\n",
            "Persian Prediction: همه‌مار را این ما ای د  یم و ست  می کرام مسا لی اختراع کندد ان اود  هدبا بول بزنیم.\n",
            "-------------------------------------------\n",
            "loss at batch number 900 : 0.00034897876321338117\n",
            "English: i've told you they've found the boat.\n",
            "Persian Translation: من به تو گفته‌ام که آن‌ها قایق کوچک را پیدا کرده‌اند.\n",
            "Persian Prediction: من به تو گفت  ام به آن ها قایق ورچک ر  تیدا برد  اند.\n",
            "-------------------------------------------\n",
            "loss at batch number 1000 : 0.00040660472586750984\n",
            "English: he was a bit of a crank: and christophe did not dislike cranks: they were a change from the horrible banality of reasonable people.\n",
            "Persian Translation: از آن گذشته آدم خلی بود و کریستف هم از آدم‌های خل خیلی بدش نمی‌آمد: در میان ابتذال دل‌آزار مردم عاقل آن‌ها برای او تنوعی بودند.\n",
            "Persian Prediction: از آن دذاتر انم اوی بو  و کریست تهم از عد ینای بو خیلی بنی ن ی‌هند  م  م  ن ابترال د. تن ن ری   ب    بن و  با نیار د   د اا . .\n",
            "-------------------------------------------\n",
            "loss at batch number 1100 : 0.0003706302959471941\n",
            "English: mommy yeah .\n",
            "Persian Translation: مامان بله .\n",
            "Persian Prediction: مامان الو .\n",
            "-------------------------------------------\n",
            "loss at batch number 1200 : 0.0003609277482610196\n",
            "English: come on youre kirk lazarus .\n",
            "Persian Translation: تو کيرک لازوراس هستي .\n",
            "Persian Prediction: تو کيري تا و دس بات  .\n",
            "-------------------------------------------\n",
            "loss at batch number 1300 : 0.0003661412338260561\n",
            "English: but just because of this darkness he felt that the one guiding clue in the darkness was his work\n",
            "Persian Translation: اما دقیقا به دلیل همین تاریکی حس می‌کرد که کارش ریسمانی است که او را از ظلمت بیرون می‌کشد.\n",
            "Persian Prediction: اما دقتقا به الی  ب ان داریکی چر می‌کرد که کردش میسمانی ایت اه ان بو بن ب مت بیرون می‌تهدا\n",
            "-------------------------------------------\n",
            "loss at batch number 1400 : 0.000326586130540818\n",
            "English: look in the glove compartment . tell me its a cheeseburger .\n",
            "Persian Translation: توي داشبورد را ببين . خواهش ميکنم بهم بگو که يک ساندويچه .\n",
            "Persian Prediction: تو  دا بهرد با بها يو بواهش ميکنه بنميايو كه يکنرنندويچه .\n",
            "-------------------------------------------\n",
            "loss at batch number 1500 : 0.0003775946097448468\n",
            "English: they were still two hundred paces from home and a gust of wind had already blown up, and every second the downpour might be looked for.\n",
            "Persian Translation: گروه هنوز دویست قدم با خانه فاصله داشت که بادو وزیدن گرفت و هر لحظه انتظار بارانی سیل آسا می‌رفت.\n",
            "Persian Prediction: گرکه همون نو نی بر یرا وانه باقاا داش  که بارر بنیدن گرفت و ام ب ل  ا  شان بارانی سیل بنت بی کدت.\n",
            "-------------------------------------------\n",
            "loss at batch number 1600 : 0.0003448098141234368\n",
            "English: they've sealed off the town.\n",
            "Persian Translation: آن‌ها شهرک را داخل این حباب مهر و موم کرده‌اند.\n",
            "Persian Prediction: آن‌ها اورکارا دا اااون نباب بهر و مرم برده‌ا د.\n",
            "-------------------------------------------\n",
            "loss at batch number 1700 : 0.0003524864441715181\n",
            "English: this truce will be honored by their sons , and sons of their sons , until the end of the time .\n",
            "Persian Translation: اين عهد را پسرهاشون هم بايد انجام بدن  و پسر هاي . پسرهاي اونا و تا آخر دنيا همين طور ادامه داره .\n",
            "Persian Prediction: اين عه  تا تاتها ا  نم رايد انجاز بده او بير هان . پسرهاش اودا ب ت  آنو بهيا همين کور بن.   ب.ند.د\n",
            "-------------------------------------------\n",
            "loss at batch number 1800 : 0.0003610398853197694\n",
            "English: stood out clearly and sharply from everyone else.\n",
            "Persian Translation: در اندیشه او با وضوح کامل از مردم دیگر متمایز می‌شدند.\n",
            "Persian Prediction: در انداشت او را ب ا رکردل از مرده دیشی دت این می‌شدند.\n",
            "-------------------------------------------\n",
            "loss at batch number 1900 : 0.0003938560257665813\n",
            "English: i reckon\n",
            "Persian Translation: من می‌گم\n",
            "Persian Prediction: من می‌کم\n",
            "-------------------------------------------\n",
            "loss at batch number 2000 : 0.0003745095746126026\n",
            "English: that napoleon expected him to be frightened\n",
            "Persian Translation: ناپلون در فکر ترساندن او است.\n",
            "Persian Prediction: ناکلون در فکهاتر تنده رز استه\n",
            "-------------------------------------------\n",
            "loss at batch number 2100 : 0.0003428911732044071\n",
            "English: rise up like lazarus .\n",
            "Persian Translation: مثل لازاروس بلند شو .\n",
            "Persian Prediction: مثل لایارون ماندابهد.\n",
            "-------------------------------------------\n",
            "loss at batch number 2200 : 0.00035762376501224935\n",
            "English: mum heads upstairs.\n",
            "Persian Translation: مامان به طبقه بالا می‌رود.\n",
            "Persian Prediction: مامان به بافت با   بی‌شید.\n",
            "-------------------------------------------\n",
            "loss at batch number 2300 : 0.0003498572332318872\n",
            "English: and as in the case of allthe other lakes seen this day, the banks to the very shore linewere sentineled with those same green pines tall, spear shaped their arms widespread like one outside his window here in lycurgus.\n",
            "Persian Translation: در سواحل این دریاچه نیز مانند همه دریاچه‌های که آن روز دیده بودند کاج‌های سوزنی بلند پایه و یشمی رنگ تا لب آن رویده بودند و مثل صنوبر پشت پنجره اتاقش در لیکرگس شاخه‌های خود را از دو طرف برگشوده بودند.\n",
            "Persian Prediction: در سوانل این اری یه ای  مانند همت دری نهااای که کن روز دیاه بود د برلادا  سوزری بلند با   ا ب  ی ب  وبانا وبی باید  به  درن ا   ب   ا م   ب  و  بن    ب  ب    و ب  ه ر   ددد ب  ب  و  ب   و  ن    ان  \n",
            "-------------------------------------------\n",
            "loss at batch number 2400 : 0.00035262774326838553\n",
            "English: it wasnt that bad .\n",
            "Persian Translation: خيلي هم بد نبود .\n",
            "Persian Prediction: خيلي هم ددون ود .\n",
            "-------------------------------------------\n",
            "loss at batch number 2500 : 0.00032185346935875714\n",
            "English: yes , i can .\n",
            "Persian Translation: چرا  من مي‌تونم .\n",
            "Persian Prediction: چرا  من ميزتونم .\n",
            "-------------------------------------------\n",
            "loss at batch number 2600 : 0.000359875411959365\n",
            "English: she shut the window, and he set off.\n",
            "Persian Translation: باز پنجره را می‌بست و شارل می‌رفت.\n",
            "Persian Prediction: باز پنگرو را می‌ اتاو دارل می‌رات.\n",
            "-------------------------------------------\n",
            "loss at batch number 2700 : 0.00035520215169526637\n",
            "English: hagrids been in loads of trouble before, and dumbledores never sacked him\n",
            "Persian Translation: هاگ رید تا حالا صد بار توی هچل افتاده ولی دامبلدور اخراجش نکرده.\n",
            "Persian Prediction: هاگ رین تا خارا با دار روی هال وستاده الی ما لل  ر اخراجادن. دن \n",
            "-------------------------------------------\n",
            "loss at batch number 2800 : 0.00035612890496850014\n",
            "English: he won't survive.\n",
            "Persian Translation: اون زنده نمي مونه,\n",
            "Persian Prediction: اون زنده نمي بود  \n",
            "-------------------------------------------\n",
            "loss at batch number 2900 : 0.00034714743378572166\n",
            "English: bring him out!\n",
            "Persian Translation: او را بیرون بیاورید!\n",
            "Persian Prediction: او را دیرون نرا!  د.\n",
            "-------------------------------------------\n",
            "loss at batch number 3000 : 0.0003586805541999638\n",
            "English: sling me a bone . hes my pal .\n",
            "Persian Translation: ولش كن اون رفيقه منه .\n",
            "Persian Prediction: ولي كن اون رااخن م ي .\n",
            "-------------------------------------------\n",
            "loss at batch number 3100 : 0.0003319434472359717\n",
            "English: the colours weren't solid? was that what one said?\n",
            "Persian Translation: این‌ گور باید گفت که رنگ‌هایش خالص نیستند\n",
            "Persian Prediction: این‌ گور باین شفت به راگ‌هاین خورص نی‌تند\n",
            "-------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "transformer.train()\n",
        "transformer.to(device)\n",
        "total_loss = 0\n",
        "num_epochs = 1\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}\")\n",
        "    iterator = iter(train_loader)\n",
        "    for batch_num, batch in enumerate(iterator):\n",
        "        transformer.train()\n",
        "        eng_batch, per_batch = batch\n",
        "        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, per_batch, num_heads)\n",
        "        optim.zero_grad()\n",
        "        persian_predictions = transformer(eng_batch,\n",
        "                                     per_batch,\n",
        "                                     encoder_self_attention_mask.to(device),\n",
        "                                     decoder_self_attention_mask.to(device),\n",
        "                                     decoder_cross_attention_mask.to(device),\n",
        "                                     encoder_start_token=False,\n",
        "                                     encoder_end_token=False,\n",
        "                                     decoder_start_token=True,\n",
        "                                     decoder_end_token=True)\n",
        "        labels = transformer.decoder.sentence_embedding.batch_tokenize(per_batch, start_token=False, end_token=True)\n",
        "        loss = criterion(\n",
        "            persian_predictions.view(-1, persian_vocab_size).to(device),\n",
        "            labels.view(-1).to(device)\n",
        "        ).to(device)\n",
        "        valid_indicies = torch.where(labels.view(-1) == persian_to_index[PADDING_TOKEN], False, True)\n",
        "        loss = loss.sum() / valid_indicies.sum()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if batch_num % 100 == 0:\n",
        "            print(f\"loss at batch number {batch_num} : {loss.item()}\")\n",
        "            print(f\"English: {eng_batch[0]}\")\n",
        "            print(f\"Persian Translation: {per_batch[0]}\")\n",
        "            persian_sentence_predicted = torch.argmax(persian_predictions[0], axis=1)\n",
        "            predicted_sentence = \"\"\n",
        "            for idx in persian_sentence_predicted:\n",
        "              if idx == persian_to_index[END_TOKEN]:\n",
        "                break\n",
        "              predicted_sentence += index_to_persian[idx.item()]\n",
        "            print(f\"Persian Prediction: {predicted_sentence}\")\n",
        "            print(\"-------------------------------------------\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
